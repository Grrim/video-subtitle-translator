"""
Serwis transkrypcji audio wykorzystujƒÖcy AssemblyAI
Obs≈Çuguje rozpoznawanie mowy z plik√≥w audio
"""

import assemblyai as aai
import os
import time
from typing import Dict, Any, List, Optional
import requests

from ..utils.logger import get_logger
from ..utils.assemblyai_features_summary import AssemblyAIFeaturesSummary

logger = get_logger(__name__)

class TranscriptionService:
    """Serwis do transkrypcji audio u≈ºywajƒÖc AssemblyAI"""
    
    def __init__(self, api_key: str):
        """
        Inicjalizuj serwis transkrypcji
        
        Args:
            api_key: Klucz API AssemblyAI
        """
        if not api_key:
            raise ValueError("Klucz API AssemblyAI jest wymagany")
        
        self.api_key = api_key
        # Ustaw klucz API w zmiennej ≈õrodowiskowej
        os.environ['ASSEMBLYAI_API_KEY'] = api_key
        aai.settings.api_key = api_key
        
        # Inicjalizuj metryki jako≈õci
        self.processing_times = []
        self.confidence_scores = []
        
        # Wy≈õwietl podsumowanie w≈ÇƒÖczonych funkcji
        logger.info("üöÄ Inicjalizacja TranscriptionService z najwy≈ºszƒÖ jako≈õciƒÖ AssemblyAI")
        AssemblyAIFeaturesSummary.print_features_summary()
        
    def transcribe_audio(self, audio_path: str, quality: str = 'premium', language: str = 'auto', enable_speaker_detection: bool = True) -> Dict[str, Any]:
        """
        Transkrybuj plik audio
        
        Args:
            audio_path: ≈öcie≈ºka do pliku audio
            quality: Jako≈õƒá transkrypcji ('standard' lub 'premium')
            language: Kod jƒôzyka lub 'auto' dla automatycznego wykrywania
            
        Returns:
            S≈Çownik z wynikami transkrypcji
        """
        try:
            start_time = time.time()
            logger.info(f"Rozpoczynam transkrypcjƒô pliku: {audio_path}")
            
            # Konfiguracja transkrypcji - NAJWY≈ªSZA JAKO≈öƒÜ z wszystkimi funkcjami
            config = aai.TranscriptionConfig(
                # === PODSTAWOWE USTAWIENIA WYSOKIEJ JAKO≈öCI ===
                language_code=language if language != 'auto' else None,
                language_detection=language == 'auto',  # Automatyczne wykrywanie jƒôzyka
                punctuate=True,                         # Interpunkcja i formatowanie tekstu
                format_text=True,                       # Formatowanie tekstu (wielkie litery, etc.)
                
                # === SPEAKER LABELS (Wykrywanie m√≥wiƒÖcych) ===
                speaker_labels=enable_speaker_detection,  # Etykiety m√≥wiƒÖcych
                speakers_expected=None,                    # Automatyczne wykrywanie liczby m√≥wiƒÖcych
                
                # === WORD-LEVEL TIMESTAMPS (Maksymalna precyzja) ===
                # Word-level timestamps sƒÖ automatycznie w≈ÇƒÖczone w AssemblyAI
                dual_channel=False,                       # Dla lepszej precyzji timestamp√≥w
                
                # === BOOST DLA NAJWY≈ªSZEJ JAKO≈öCI ===
                word_boost=[],                           # Lista s≈Ç√≥w do wzmocnienia (mo≈ºna dodaƒá specjalne terminy)
                boost_param='high',                      # Wysoki poziom wzmocnienia jako≈õci
                
                # === DODATKOWE FUNKCJE AI (Premium) ===
                auto_highlights=True,                    # Automatyczne wyr√≥≈ºnienia kluczowych fragment√≥w
                auto_chapters=True,                      # Automatyczne rozdzia≈Çy/segmentacja
                sentiment_analysis=True,                 # Analiza sentymentu wypowiedzi
                entity_detection=True,                   # Wykrywanie encji (nazwy, miejsca, organizacje)
                iab_categories=True,                     # Kategoryzacja tre≈õci IAB
                content_safety=True,                     # Wykrywanie niebezpiecznych tre≈õci
                
                # === USTAWIENIA PRYWATNO≈öCI I FILTROWANIA ===
                filter_profanity=False,                 # Nie filtruj wulgaryzm√≥w (dla dok≈Çadno≈õci)
                redact_pii=False,                        # Nie ukrywaj danych osobowych
                redact_pii_audio=False,                  # Nie ukrywaj w audio
                redact_pii_policies=None,                # Brak polityk ukrywania
                redact_pii_sub='***',                    # Zastƒôpowanie (je≈õli w≈ÇƒÖczone)
                
                # === USTAWIENIA AUDIO ===
                audio_start_from=None,                   # Start od poczƒÖtku
                audio_end_at=None,                       # Do ko≈Ñca pliku
                
                # === WEBHOOK (opcjonalne) ===
                webhook_url=None,
                webhook_auth_header_name=None,
                webhook_auth_header_value=None,
                
                # === DODATKOWE USTAWIENIA JAKO≈öCI ===
                speech_threshold=None,                   # Automatyczny pr√≥g wykrywania mowy
                disfluencies=False,                      # Nie uwzglƒôdniaj zacinania siƒô
                # multichannel nie istnieje - u≈ºywamy dual_channel powy≈ºej
            )
            
            # Utw√≥rz transkryptor
            transcriber = aai.Transcriber(config=config)
            
            # Rozpocznij transkrypcjƒô
            transcript = transcriber.transcribe(audio_path)
            
            # Sprawd≈∫ status
            if transcript.status == aai.TranscriptStatus.error:
                raise Exception(f"B≈ÇƒÖd transkrypcji: {transcript.error}")
            
            # Oblicz czas przetwarzania
            processing_time = time.time() - start_time
            self.processing_times.append(processing_time)
            
            # Przygotuj wynik z rozszerzonymi metrykami
            confidence = getattr(transcript, 'confidence', 0.0)
            self.confidence_scores.append(confidence)
            
            result = {
                'id': getattr(transcript, 'id', 'unknown'),
                'text': transcript.text or '',
                'confidence': confidence,
                'language_code': getattr(transcript, 'language_code', 'unknown'),
                'audio_duration': getattr(transcript, 'audio_duration', 0),
                'segments': self._extract_segments(transcript, enable_speaker_detection),
                'words': self._extract_words_with_precision(transcript),
                'status': getattr(transcript.status, 'value', 'completed') if hasattr(transcript, 'status') else 'completed',
                'processing_time': processing_time,
                'quality_metrics': {
                    'confidence_score': confidence,
                    'processing_time': processing_time,
                    'word_count': len(transcript.text.split()) if transcript.text else 0,
                    'segment_count': len(self._extract_segments(transcript, enable_speaker_detection)),
                    'language_detected': getattr(transcript, 'language_code', 'unknown'),
                    'audio_duration_seconds': getattr(transcript, 'audio_duration', 0) / 1000.0 if getattr(transcript, 'audio_duration', 0) else 0
                }
            }
            
            # === DODATKOWE INFORMACJE PREMIUM (Wszystkie funkcje AI) ===
            # Auto Highlights - kluczowe fragmenty
            if hasattr(transcript, 'auto_highlights') and transcript.auto_highlights:
                result['highlights'] = [
                    {
                        'text': highlight.text,
                        'count': highlight.count,
                        'rank': highlight.rank,
                        'timestamps': getattr(highlight, 'timestamps', [])
                    }
                    for highlight in transcript.auto_highlights.results
                ]
                logger.info(f"‚ú® Wykryto {len(result['highlights'])} kluczowych fragment√≥w")
            
            # Sentiment Analysis - analiza sentymentu
            if hasattr(transcript, 'sentiment_analysis') and transcript.sentiment_analysis:
                result['sentiment'] = [
                    {
                        'text': sentiment.text,
                        'sentiment': sentiment.sentiment.value,
                        'confidence': sentiment.confidence,
                        'start': sentiment.start / 1000.0,
                        'end': sentiment.end / 1000.0
                    }
                    for sentiment in transcript.sentiment_analysis
                ]
                logger.info(f"üòä Przeanalizowano sentyment dla {len(result['sentiment'])} fragment√≥w")
            
            # Entity Detection - wykrywanie encji
            if hasattr(transcript, 'entities') and transcript.entities:
                result['entities'] = [
                    {
                        'text': entity.text,
                        'entity_type': entity.entity_type.value,
                        'start': entity.start / 1000.0,
                        'end': entity.end / 1000.0
                    }
                    for entity in transcript.entities
                ]
                logger.info(f"üè∑Ô∏è Wykryto {len(result['entities'])} encji (nazwy, miejsca, organizacje)")
            
            # Auto Chapters - automatyczne rozdzia≈Çy
            if hasattr(transcript, 'chapters') and transcript.chapters:
                result['chapters'] = [
                    {
                        'summary': chapter.summary,
                        'headline': chapter.headline,
                        'gist': chapter.gist,
                        'start': chapter.start / 1000.0,
                        'end': chapter.end / 1000.0
                    }
                    for chapter in transcript.chapters
                ]
                logger.info(f"üìö Utworzono {len(result['chapters'])} automatycznych rozdzia≈Ç√≥w")
            
            # IAB Categories - kategoryzacja tre≈õci
            if hasattr(transcript, 'iab_categories') and transcript.iab_categories:
                result['categories'] = {
                    'summary': getattr(transcript.iab_categories, 'summary', {}),
                    'results': [
                        {
                            'text': cat.text,
                            'labels': [
                                {
                                    'relevance': label.relevance,
                                    'label': label.label
                                }
                                for label in cat.labels
                            ],
                            'timestamp': {
                                'start': cat.timestamp.start / 1000.0,
                                'end': cat.timestamp.end / 1000.0
                            }
                        }
                        for cat in transcript.iab_categories.results
                    ]
                }
                logger.info(f"üìÇ Skategoryzowano tre≈õƒá wed≈Çug standardu IAB")
            
            # Content Safety - bezpiecze≈Ñstwo tre≈õci
            if hasattr(transcript, 'content_safety_labels') and transcript.content_safety_labels:
                result['content_safety'] = {
                    'summary': getattr(transcript.content_safety_labels, 'summary', {}),
                    'results': [
                        {
                            'text': safety.text,
                            'labels': [
                                {
                                    'confidence': label.confidence,
                                    'severity': label.severity,
                                    'label': label.label
                                }
                                for label in safety.labels
                            ],
                            'timestamp': {
                                'start': safety.timestamp.start / 1000.0,
                                'end': safety.timestamp.end / 1000.0
                            }
                        }
                        for safety in transcript.content_safety_labels.results
                    ]
                }
                logger.info(f"üõ°Ô∏è Przeanalizowano bezpiecze≈Ñstwo tre≈õci")
            
            # Waliduj czy wszystkie funkcje zosta≈Çy zwr√≥cone
            warnings = AssemblyAIFeaturesSummary.validate_api_features(result)
            
            logger.info(f"‚úÖ Transkrypcja zako≈Ñczona pomy≈õlnie!")
            logger.info(f"üìä Statystyki: {len(result['text'])} znak√≥w, {len(result.get('words', []))} s≈Ç√≥w, {len(result.get('segments', []))} segment√≥w")
            logger.info(f"üéØ Pewno≈õƒá: {result['confidence']:.1%}, Czas: {result['processing_time']:.1f}s")
            
            return result
            
        except Exception as e:
            logger.error(f"B≈ÇƒÖd podczas transkrypcji: {e}")
            # Rzuƒá wyjƒÖtek zamiast zwracaƒá b≈Çƒôdny wynik
            # To pozwoli aplikacji obs≈Çu≈ºyƒá b≈ÇƒÖd odpowiednio
            raise Exception(f"Transkrypcja nie powiod≈Ça siƒô: {str(e)}")
    
    def _extract_segments(self, transcript, enable_speaker_detection: bool = True) -> List[Dict[str, Any]]:
        """
        WyciƒÖgnij segmenty z transkrypcji
        
        Args:
            transcript: Obiekt transkrypcji AssemblyAI
            
        Returns:
            Lista segment√≥w z czasami
        """
        segments = []
        
        if hasattr(transcript, 'utterances') and transcript.utterances and enable_speaker_detection:
            # Je≈õli mamy utterances (segmenty m√≥wc√≥w)
            for i, utterance in enumerate(transcript.utterances):
                segments.append({
                    'text': utterance.text,
                    'start': utterance.start / 1000.0,  # Konwersja z ms na sekundy
                    'end': utterance.end / 1000.0,
                    'confidence': utterance.confidence,
                    'speaker': getattr(utterance, 'speaker', f'Speaker_{chr(65+i%26)}'),  # A, B, C, etc.
                    'speaker_confidence': getattr(utterance, 'confidence', 0.8),
                    'segment_id': i,
                    'word_count': len(utterance.text.split()) if utterance.text else 0
                })
        elif hasattr(transcript, 'words') and transcript.words:
            # Je≈õli mamy tylko s≈Çowa, grupuj je w segmenty
            current_segment = []
            segment_start = None
            segment_end = None
            
            for word in transcript.words:
                if segment_start is None:
                    segment_start = word.start / 1000.0
                
                current_segment.append(word.text)
                segment_end = word.end / 1000.0
                
                # Utw√≥rz nowy segment co ~3-4 sekundy lub po 6-8 s≈Ç√≥w dla lepszej czytelno≈õci
                if (segment_end - segment_start > 3.5) or (len(current_segment) >= 7):
                    segments.append({
                        'text': ' '.join(current_segment),
                        'start': segment_start,
                        'end': segment_end,
                        'confidence': word.confidence,
                        'speaker': 'A'
                    })
                    
                    current_segment = []
                    segment_start = None
            
            # Dodaj ostatni segment je≈õli istnieje
            if current_segment:
                segments.append({
                    'text': ' '.join(current_segment),
                    'start': segment_start,
                    'end': segment_end,
                    'confidence': 0.9,  # Domy≈õlna pewno≈õƒá
                    'speaker': 'A'
                })
        else:
            # Fallback - jeden segment z ca≈Çym tekstem
            audio_duration = getattr(transcript, 'audio_duration', 0)
            segments.append({
                'text': transcript.text or '',
                'start': 0.0,
                'end': audio_duration / 1000.0 if audio_duration else 10.0,
                'confidence': getattr(transcript, 'confidence', 0.9),
                'speaker': 'A'
            })
        
        return segments
    
    def _extract_words_with_precision(self, transcript) -> List[Dict[str, Any]]:
        """
        WyciƒÖgnij s≈Çowa z MAKSYMALNƒÑ PRECYZJƒÑ word-level timestamps
        
        Args:
            transcript: Obiekt transkrypcji AssemblyAI
            
        Returns:
            Lista s≈Ç√≥w z precyzyjnymi timestampami
        """
        words = []
        
        if hasattr(transcript, 'words') and transcript.words:
            logger.info(f"Wykryto {len(transcript.words)} s≈Ç√≥w z word-level timestamps")
            
            for i, word in enumerate(transcript.words):
                # Konwertuj z milisekund na sekundy z wysokƒÖ precyzjƒÖ
                start_seconds = word.start / 1000.0
                end_seconds = word.end / 1000.0
                
                # Waliduj timestampy
                if end_seconds <= start_seconds:
                    # Napraw nieprawid≈Çowe timestampy
                    end_seconds = start_seconds + 0.1  # Minimalna d≈Çugo≈õƒá 100ms
                
                word_data = {
                    'text': word.text,
                    'start': round(start_seconds, 3),  # Precyzja do milisekund
                    'end': round(end_seconds, 3),
                    'confidence': getattr(word, 'confidence', 0.9),
                    'word_index': i,  # Indeks s≈Çowa
                    'duration': round(end_seconds - start_seconds, 3),
                    'speaker': getattr(word, 'speaker', 'A'),  # M√≥wiƒÖcy (je≈õli dostƒôpne)
                    'is_punctuated': any(p in word.text for p in '.,!?;:'),  # Czy ma interpunkcjƒô
                }
                
                words.append(word_data)
            
            # Sprawd≈∫ jako≈õƒá word-level timestamps
            self._validate_word_timestamps(words)
            
        else:
            logger.warning("Brak word-level timestamps - u≈ºywam fallback z segment√≥w")
            words = self._fallback_words_from_segments(transcript)
        
        return words
    
    def _validate_word_timestamps(self, words: List[Dict[str, Any]]):
        """
        Waliduj jako≈õƒá word-level timestamps
        
        Args:
            words: Lista s≈Ç√≥w z timestampami
        """
        if not words:
            return
        
        issues = []
        
        # Sprawd≈∫ nak≈Çadanie siƒô s≈Ç√≥w
        for i in range(len(words) - 1):
            current_end = words[i]['end']
            next_start = words[i + 1]['start']
            
            if current_end > next_start:
                issues.append(f"Nak≈Çadanie s≈Ç√≥w {i}-{i+1}")
        
        # Sprawd≈∫ bardzo kr√≥tkie s≈Çowa
        short_words = [w for w in words if w['duration'] < 0.05]  # < 50ms
        if short_words:
            issues.append(f"{len(short_words)} bardzo kr√≥tkich s≈Ç√≥w")
        
        # Sprawd≈∫ bardzo d≈Çugie s≈Çowa
        long_words = [w for w in words if w['duration'] > 3.0]  # > 3s
        if long_words:
            issues.append(f"{len(long_words)} bardzo d≈Çugich s≈Ç√≥w")
        
        if issues:
            logger.warning(f"Problemy z word-level timestamps: {', '.join(issues)}")
        else:
            logger.info("‚úÖ Word-level timestamps sƒÖ wysokiej jako≈õci")
    
    def _fallback_words_from_segments(self, transcript) -> List[Dict[str, Any]]:
        """
        Fallback: stw√≥rz s≈Çowa z segment√≥w gdy brak word-level timestamps
        
        Args:
            transcript: Obiekt transkrypcji
            
        Returns:
            Lista oszacowanych s≈Ç√≥w
        """
        words = []
        
        if hasattr(transcript, 'utterances') and transcript.utterances:
            segments = transcript.utterances
        else:
            # U≈ºyj podstawowych segment√≥w
            segments = getattr(transcript, 'segments', [])
        
        word_index = 0
        
        for segment in segments:
            segment_text = getattr(segment, 'text', '')
            segment_start = getattr(segment, 'start', 0) / 1000.0
            segment_end = getattr(segment, 'end', 0) / 1000.0
            segment_confidence = getattr(segment, 'confidence', 0.8)
            
            # Podziel segment na s≈Çowa
            segment_words = segment_text.split()
            
            if not segment_words:
                continue
            
            # Roz≈Ç√≥≈º czas r√≥wnomiernie miƒôdzy s≈Çowa
            segment_duration = segment_end - segment_start
            time_per_word = segment_duration / len(segment_words)
            
            for i, word_text in enumerate(segment_words):
                word_start = segment_start + (i * time_per_word)
                word_end = word_start + time_per_word
                
                word_data = {
                    'text': word_text,
                    'start': round(word_start, 3),
                    'end': round(word_end, 3),
                    'confidence': segment_confidence,
                    'word_index': word_index,
                    'duration': round(time_per_word, 3),
                    'speaker': getattr(segment, 'speaker', 'A'),
                    'is_punctuated': any(p in word_text for p in '.,!?;:'),
                    'estimated': True  # Oznacz jako oszacowane
                }
                
                words.append(word_data)
                word_index += 1
        
        logger.info(f"Utworzono {len(words)} oszacowanych s≈Ç√≥w z segment√≥w")
        return words
    
    def get_supported_languages(self) -> Dict[str, str]:
        """
        Pobierz listƒô obs≈Çugiwanych jƒôzyk√≥w
        
        Returns:
            S≈Çownik z kodami i nazwami jƒôzyk√≥w
        """
        return {
            'auto': 'Automatyczne wykrywanie',
            'en': 'Angielski',
            'es': 'Hiszpa≈Ñski',
            'fr': 'Francuski',
            'de': 'Niemiecki',
            'it': 'W≈Çoski',
            'pt': 'Portugalski',
            'nl': 'Holenderski',
            'hi': 'Hindi',
            'ja': 'Japo≈Ñski',
            'zh': 'Chi≈Ñski',
            'ko': 'Korea≈Ñski',
            'ru': 'Rosyjski',
            'ar': 'Arabski',
            'tr': 'Turecki',
            'pl': 'Polski',
            'uk': 'Ukrai≈Ñski',
            'vi': 'Wietnamski',
            'th': 'Tajski'
        }
    
    def check_api_status(self) -> bool:
        """
        Sprawd≈∫ status API AssemblyAI
        
        Returns:
            True je≈õli API jest dostƒôpne, False w przeciwnym razie
        """
        try:
            # Sprawd≈∫ dostƒôpno≈õƒá API przez prosty request
            headers = {'authorization': self.api_key}
            response = requests.get('https://api.assemblyai.com/v2/transcript', headers=headers)
            return response.status_code == 200
            
        except Exception as e:
            logger.error(f"B≈ÇƒÖd podczas sprawdzania statusu API: {e}")
            return False