"""
G≈Ç√≥wna aplikacja Streamlit dla systemu t≈Çumaczenia napis√≥w wideo
"""

import streamlit as st
import os
from pathlib import Path
import tempfile
import time
from typing import Optional, Dict, Any, List, Callable, Tuple

from .services.video_processor import VideoProcessor
from .services.transcription_service import TranscriptionService
from .services.translation_service import TranslationService
from .services.subtitle_generator import SubtitleGenerator
from .services.quality_control import QualityController, QualityFlag
from .services.retry_manager import RetryManager, RetryConfig, SegmentReprocessor
from .services.audio_sync_manager import AudioSyncManager
from .services.word_level_sync import WordLevelSynchronizer
from .services.advanced_word_processor import AdvancedWordProcessor
from .services.smooth_subtitle_renderer import SmoothSubtitleRenderer, SmoothSubtitleConfig
from .services.utterance_segmentation import UtteranceSegmentator
from .services.timestamp_debugger import TimestampDebugger
from .utils.config import Config
from .utils.logger import get_logger
from .components.file_uploader import FileUploader
from .components.language_selector import LanguageSelector
from .components.progress_tracker import ProgressTracker
from .components.video_player import VideoPlayer

logger = get_logger(__name__)

class VideoSubtitleApp:
    """G≈Ç√≥wna klasa aplikacji do t≈Çumaczenia napis√≥w wideo"""
    
    def __init__(self):
        self.config = Config()
        self.video_processor = VideoProcessor()
        self.transcription_service = TranscriptionService(self.config.assemblyai_api_key)
        self.translation_service = TranslationService(self.config.deepl_api_key)
        self.subtitle_generator = SubtitleGenerator()
        
        # Nowe komponenty kontroli jako≈õci
        self.quality_controller = QualityController()
        self.retry_manager = RetryManager(RetryConfig(max_retries=3, confidence_threshold=0.7))
        self.segment_reprocessor = SegmentReprocessor(self.retry_manager)
        self.audio_sync_manager = AudioSyncManager()
        self.word_level_sync = WordLevelSynchronizer()
        self.advanced_word_processor = AdvancedWordProcessor()
        self.smooth_renderer = SmoothSubtitleRenderer()
        self.utterance_segmentator = UtteranceSegmentator()
        self.timestamp_debugger = TimestampDebugger()
        
    def run(self):
        """Uruchom g≈Ç√≥wnƒÖ aplikacjƒô"""
        self._setup_page()
        self._render_sidebar()
        self._render_main_content()
    
    def _setup_page(self):
        """Konfiguracja strony Streamlit"""
        st.title("üé¨ System T≈Çumaczenia Napis√≥w Wideo")
        st.markdown("""
        **Profesjonalny system t≈Çumaczenia mowy w tre≈õciach wideo**
        
        Wykorzystuje:
        - üé§ **AssemblyAI** do rozpoznawania mowy (ASR)
        - üåç **DeepL** do t≈Çumaczenia maszynowego (MT)
        - üé• **FFmpeg** do przetwarzania wideo
        """)
        
        # Sprawd≈∫ konfiguracjƒô API
        if not self._check_api_configuration():
            st.stop()
    
    def _check_api_configuration(self) -> bool:
        """Sprawd≈∫ czy klucze API sƒÖ skonfigurowane"""
        missing_keys = []
        
        if not self.config.assemblyai_api_key:
            missing_keys.append("AssemblyAI API Key")
        
        if not self.config.deepl_api_key:
            missing_keys.append("DeepL API Key")
        
        if missing_keys:
            st.error(f"‚ùå Brakuje kluczy API: {', '.join(missing_keys)}")
            st.info("""
            **Jak skonfigurowaƒá klucze API:**
            
            1. Stw√≥rz plik `.env` w g≈Ç√≥wnym katalogu projektu
            2. Dodaj nastƒôpujƒÖce linie:
            ```
            ASSEMBLYAI_API_KEY=tw√≥j_klucz_assemblyai
            DEEPL_API_KEY=tw√≥j_klucz_deepl
            ```
            
            **Gdzie uzyskaƒá klucze:**
            - AssemblyAI: https://www.assemblyai.com/
            - DeepL: https://www.deepl.com/pro-api
            """)
            return False
        
        return True
    
    def _render_sidebar(self):
        """Renderuj panel boczny z ustawieniami"""
        with st.sidebar:
            st.header("‚öôÔ∏è Ustawienia")
            
            # Wyb√≥r jƒôzyka docelowego
            target_language = LanguageSelector.render_target_language_selector()
            st.session_state.target_language = target_language
            
            # Ustawienia jako≈õci
            st.subheader("üéØ Jako≈õƒá przetwarzania")
            
            transcription_quality = st.selectbox(
                "Jako≈õƒá transkrypcji",
                ["standard", "premium"],
                help="Premium oferuje lepszƒÖ jako≈õƒá ale jest dro≈ºszy"
            )
            
            translation_formality = st.selectbox(
                "Formalno≈õƒá t≈Çumaczenia",
                ["default", "more", "less"],
                help="Poziom formalno≈õci w t≈Çumaczeniu"
            )
            
            # Nowe ustawienia kontroli jako≈õci
            st.subheader("üîç Kontrola jako≈õci")
            
            enable_quality_control = st.checkbox(
                "W≈ÇƒÖcz kontrolƒô jako≈õci",
                value=True,
                help="Automatyczna walidacja i kontrola jako≈õci na ka≈ºdym etapie"
            )
            
            enable_speaker_detection = st.checkbox(
                "Wykrywanie m√≥wiƒÖcych",
                value=True,
                help="Identyfikacja r√≥≈ºnych m√≥wiƒÖcych w nagraniu"
            )
            
            enable_auto_retry = st.checkbox(
                "Automatyczne ponowne pr√≥by",
                value=True,
                help="Automatyczne ponowne przetwarzanie w przypadku b≈Çƒôd√≥w"
            )
            
            enable_audio_sync = st.checkbox(
                "Precyzyjna synchronizacja audio",
                value=True,
                help="Automatyczna korekta synchronizacji miƒôdzy d≈∫wiƒôkiem a napisami"
            )
            
            enable_word_level = st.checkbox(
                "Napisy na poziomie s≈Ç√≥w",
                value=True,
                help="Wy≈õwietlaj s≈Çowa stopniowo, jak dochodzƒÖ do zdania"
            )
            
            enable_advanced_processing = st.checkbox(
                "üöÄ Zaawansowany post-processing",
                value=True,
                help="Napraw nak≈Çadania, minimalne przerwy (20ms), stabilizacja blok√≥w (38 s≈Ç√≥w), korekta offsetu"
            )
            
            enable_utterance_segmentation = st.checkbox(
                "Segmentacja na utterances (wypowiedzi)",
                value=True,
                help="Automatyczny podzia≈Ç na naturalne wypowiedzi na podstawie pauz w mowie"
            )
            
            word_display_mode = st.selectbox(
                "Tryb wy≈õwietlania s≈Ç√≥w",
                ["smooth_progressive", "stable_blocks", "fade_transitions", "youtube_style", "individual"],
                help="Smooth progressive: p≈Çynne bez migotania, Stable blocks: stabilne bloki, Fade transitions: z efektami"
            )
            
            max_words_on_screen = st.slider(
                "Maksymalna liczba s≈Ç√≥w na ekranie",
                3, 15, 8,
                help="Ile s≈Ç√≥w mo≈ºe byƒá jednocze≈õnie widocznych (jak na YouTube)"
            )
            
            # Ustawienia jako≈õci napis√≥w
            st.subheader("‚ú® Jako≈õƒá napis√≥w")
            
            enable_anti_flicker = st.checkbox(
                "Eliminacja migotania",
                value=True,
                help="Usuwa migotanie i poprawia p≈Çynno≈õƒá napis√≥w"
            )
            
            subtitle_quality = st.selectbox(
                "Jako≈õƒá napis√≥w",
                ["standard", "high", "premium"],
                index=1,
                help="Standard: podstawowe SRT, High: SRT z stylizacjƒÖ, Premium: ASS z efektami"
            )
            
            min_display_duration = st.slider(
                "Minimalna d≈Çugo≈õƒá wy≈õwietlania (s)",
                0.2, 1.0, 0.4, 0.1,
                help="Minimalna d≈Çugo≈õƒá wy≈õwietlania ka≈ºdego napisu"
            )
            
            confidence_threshold = st.slider(
                "Pr√≥g pewno≈õci",
                0.5, 1.0, 0.7, 0.05,
                help="Minimalny poziom pewno≈õci dla akceptacji wynik√≥w"
            )
            
            # Ustawienia napis√≥w
            st.subheader("üìù Ustawienia napis√≥w")
            
            subtitle_format = st.selectbox(
                "Format napis√≥w",
                ["SRT", "VTT", "ASS"],
                help="Format pliku z napisami"
            )
            
            max_chars_per_line = st.slider(
                "Maksymalna d≈Çugo≈õƒá linii",
                20, 80, 42,
                help="Maksymalna liczba znak√≥w w linii napisu"
            )
            
            # Zapisz ustawienia w session_state
            st.session_state.update({
                'transcription_quality': transcription_quality,
                'translation_formality': translation_formality,
                'subtitle_format': subtitle_format,
                'max_chars_per_line': max_chars_per_line,
                'enable_quality_control': enable_quality_control,
                'enable_speaker_detection': enable_speaker_detection,
                'enable_auto_retry': enable_auto_retry,
                'enable_audio_sync': enable_audio_sync,
                'enable_word_level': enable_word_level,
                'enable_advanced_processing': enable_advanced_processing,
                'enable_utterance_segmentation': enable_utterance_segmentation,
                'word_display_mode': word_display_mode,
                'max_words_on_screen': max_words_on_screen,
                'enable_anti_flicker': enable_anti_flicker,
                'subtitle_quality': subtitle_quality,
                'min_display_duration': min_display_duration,
                'confidence_threshold': confidence_threshold
            })
    
    def _render_main_content(self):
        """Renderuj g≈Ç√≥wnƒÖ zawarto≈õƒá aplikacji"""
        # Upload pliku wideo
        uploaded_file = FileUploader.render_video_uploader()
        
        if uploaded_file is not None:
            self._process_video_workflow(uploaded_file)
    
    def _process_video_workflow(self, uploaded_file):
        """G≈Ç√≥wny workflow przetwarzania wideo"""
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("üìπ PodglƒÖd wideo")
            
            # Zapisz przes≈Çany plik tymczasowo
            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
                tmp_file.write(uploaded_file.read())
                video_path = tmp_file.name
            
            # Wy≈õwietl odtwarzacz wideo
            VideoPlayer.render_video_player(video_path)
            
            # Przycisk do rozpoczƒôcia przetwarzania
            if st.button("üöÄ Rozpocznij przetwarzanie", type="primary", use_container_width=True):
                self._start_processing(video_path, uploaded_file.name)
        
        with col2:
            st.subheader("‚ÑπÔ∏è Informacje o pliku")
            
            # Informacje o pliku
            file_info = self.video_processor.get_video_info(video_path)
            if file_info:
                st.write(f"**Nazwa:** {uploaded_file.name}")
                st.write(f"**Rozmiar:** {uploaded_file.size / (1024*1024):.1f} MB")
                st.write(f"**Czas trwania:** {file_info.get('duration', 'N/A')}")
                st.write(f"**Rozdzielczo≈õƒá:** {file_info.get('resolution', 'N/A')}")
                st.write(f"**FPS:** {file_info.get('fps', 'N/A')}")
    
    def _start_processing(self, video_path: str, original_filename: str):
        """Rozpocznij przetwarzanie wideo"""
        progress_tracker = ProgressTracker()
        
        try:
            # Krok 1: Ekstrakcja audio
            progress_tracker.update_progress(0.1, "üéµ Ekstraktowanie audio z wideo...")
            audio_path = self.video_processor.extract_audio(video_path)
            
            # Krok 2: Transkrypcja
            progress_tracker.update_progress(0.3, "üé§ Transkrypcja audio (AssemblyAI)...")
            transcript = self.transcription_service.transcribe_audio(
                audio_path,
                quality=st.session_state.get('transcription_quality', 'standard')
            )
            
            # Krok 3: T≈Çumaczenie
            progress_tracker.update_progress(0.6, "üåç T≈Çumaczenie tekstu (DeepL)...")
            translated_text = self.translation_service.translate_text(
                transcript['text'],
                target_language=st.session_state.get('target_language', 'PL'),
                formality=st.session_state.get('translation_formality', 'default')
            )
            
            # Krok 4: Precyzyjna synchronizacja audio-napisy
            if st.session_state.get('enable_audio_sync', True):
                progress_tracker.update_progress(0.65, "üéµ Analiza cech audio...")
                
                # Analizuj cechy audio
                audio_features = self.audio_sync_manager.analyze_audio_features(audio_path)
                
                progress_tracker.update_progress(0.7, "üîÑ Obliczanie korekty synchronizacji...")
                
                # Przygotuj segmenty z t≈Çumaczeniem dla synchronizacji
                segments_for_sync = []
                for i, segment in enumerate(transcript['segments']):
                    sync_segment = segment.copy()
                    # U≈ºyj prostego podzia≈Çu t≈Çumaczenia na segmenty
                    words = translated_text.split()
                    words_per_segment = len(words) // len(transcript['segments'])
                    start_word = i * words_per_segment
                    end_word = (i + 1) * words_per_segment if i < len(transcript['segments']) - 1 else len(words)
                    sync_segment['text'] = ' '.join(words[start_word:end_word])
                    segments_for_sync.append(sync_segment)
                
                # Oblicz korekcjƒô synchronizacji
                sync_correction = self.audio_sync_manager.calculate_sync_offset(
                    audio_features, segments_for_sync
                )
                
                if sync_correction.confidence > 0.3:  # Obni≈ºony pr√≥g
                    if sync_correction.confidence > 0.6:
                        st.success(f"üéØ Wykryto precyzyjne przesuniƒôcie: {sync_correction.offset_seconds:.2f}s "
                                 f"(pewno≈õƒá: {sync_correction.confidence:.1%}, metoda: {sync_correction.method})")
                    else:
                        st.info(f"üéØ Wykryto przybli≈ºone przesuniƒôcie: {sync_correction.offset_seconds:.2f}s "
                               f"(pewno≈õƒá: {sync_correction.confidence:.1%}, metoda: {sync_correction.method})")
                    
                    # Zastosuj korekcjƒô synchronizacji
                    corrected_segments = self.audio_sync_manager.apply_sync_correction(
                        segments_for_sync, sync_correction
                    )
                    
                    # Precyzyjne dostrojenie timingu
                    corrected_segments = self.audio_sync_manager.fine_tune_segment_timing(
                        corrected_segments, audio_features
                    )
                    
                    # Waliduj jako≈õƒá synchronizacji
                    sync_quality = self.audio_sync_manager.validate_sync_quality(
                        corrected_segments, audio_features
                    )
                    
                    if sync_quality['sync_quality'] in ['excellent', 'good']:
                        st.success(f"‚úÖ Synchronizacja: {sync_quality['sync_quality']} "
                                  f"(pokrycie: {sync_quality['coverage']:.1%})")
                    else:
                        st.warning(f"‚ö†Ô∏è Synchronizacja: {sync_quality['sync_quality']} "
                                  f"(pokrycie: {sync_quality['coverage']:.1%})")
                    
                    # U≈ºyj skorygowanych segment√≥w
                    transcript['segments'] = corrected_segments
                else:
                    st.warning(f"‚ö†Ô∏è Bardzo niska pewno≈õƒá synchronizacji ({sync_correction.confidence:.1%})")
                    st.info("üí° U≈ºywam oryginalnych czas√≥w segment√≥w - synchronizacja mo≈ºe byƒá mniej precyzyjna")
                    # Nie stosuj korekty, ale kontynuuj z oryginalnymi segmentami
            
            # Krok 5: Segmentacja na utterances (je≈õli w≈ÇƒÖczona)
            if st.session_state.get('enable_utterance_segmentation', True):
                progress_tracker.update_progress(0.75, "üó£Ô∏è Segmentacja na naturalne wypowiedzi...")
                
                # Segmentuj na utterances
                utterance_segments = self.utterance_segmentator.segment_by_utterances(transcript)
                
                # Pobierz statystyki pauz
                pause_stats = self.utterance_segmentator.get_pause_statistics(utterance_segments)
                
                if pause_stats:
                    st.info(f"üéØ Wykryto {pause_stats['total_pauses']} naturalnych pauz "
                           f"(≈õrednia: {pause_stats['average_pause']:.2f}s, "
                           f"maksymalna: {pause_stats['max_pause']:.2f}s)")
                else:
                    st.info("üéØ Segmentacja na utterances zako≈Ñczona")
                
                # Konwertuj utterances z powrotem do formatu transcript
                transcript['segments'] = self._convert_utterances_to_segments(utterance_segments)
                transcript['utterances'] = utterance_segments
                
                # Zapisz informacje o utterances
                st.session_state['utterance_segments'] = utterance_segments
                st.session_state['pause_statistics'] = pause_stats
            
            # Krok 6: Generowanie napis√≥w (na poziomie s≈Ç√≥w lub tradycyjnie)
            if st.session_state.get('enable_word_level', True):
                progress_tracker.update_progress(0.8, "üìù Generowanie napis√≥w na poziomie s≈Ç√≥w...")
                
                # Ustaw parametry wy≈õwietlania
                self.word_level_sync.max_words_on_screen = st.session_state.get('max_words_on_screen', 8)
                
                # Konfiguruj renderer p≈Çynnych napis√≥w
                smooth_config = SmoothSubtitleConfig(
                    min_display_duration=st.session_state.get('min_display_duration', 0.4),
                    max_words_per_line=st.session_state.get('max_words_on_screen', 8),
                    font_size=18 if st.session_state.get('subtitle_quality', 'high') == 'standard' else 20
                )
                self.smooth_renderer.config = smooth_config
                
                # NOWY: Zaawansowany post-processing je≈õli w≈ÇƒÖczony
                if st.session_state.get('enable_advanced_processing', True):
                    st.info("üöÄ Stosowanie zaawansowanego post-processingu...")
                    
                    # U≈ºyj zaawansowanego procesora s≈Ç√≥w
                    stabilized_blocks = self.advanced_word_processor.process_word_level_transcription(
                        transcript, audio_file_path if 'audio_file_path' in locals() else None
                    )
                    
                    if stabilized_blocks:
                        st.success(f"‚úÖ Utworzono {len(stabilized_blocks)} stabilizowanych blok√≥w (38 s≈Ç√≥w ka≈ºdy)")
                        
                        # Konwertuj stabilizowane bloki do formatu word_segments dla kompatybilno≈õci
                        word_segments = self._convert_stabilized_blocks_to_segments(stabilized_blocks)
                        
                        # Wy≈õwietl informacje o post-processingu
                        with st.expander("üìä Szczeg√≥≈Çy zaawansowanego post-processingu"):
                            st.write(f"**Liczba blok√≥w:** {len(stabilized_blocks)}")
                            st.write(f"**≈örednia liczba s≈Ç√≥w na blok:** {sum(len(block.words) for block in stabilized_blocks) / len(stabilized_blocks):.1f}")
                            st.write(f"**Nak≈Çadanie miƒôdzy blokami:** {self.advanced_word_processor.block_overlap*1000:.0f}ms")
                            st.write(f"**Minimalna przerwa miƒôdzy s≈Çowami:** {self.advanced_word_processor.min_word_gap*1000:.0f}ms")
                            st.write(f"**Minimalna d≈Çugo≈õƒá wy≈õwietlania s≈Çowa:** {self.advanced_word_processor.min_word_duration*1000:.0f}ms")
                    else:
                        st.warning("‚ö†Ô∏è Zaawansowany post-processing nieudany, u≈ºywam standardowego przetwarzania")
                        # Fallback do standardowego przetwarzania
                        word_segments = self.word_level_sync.create_word_level_subtitles(
                            transcript, translated_text
                        )
                else:
                    # Standardowe przetwarzanie word-level
                    word_segments = self.word_level_sync.create_word_level_subtitles(
                        transcript, translated_text
                    )
                
                # Konwertuj do formatu kompatybilnego z smooth renderer
                smooth_segments = self._convert_to_smooth_format(word_segments)
                
                # Wybierz tryb wy≈õwietlania
                display_mode = st.session_state.get('word_display_mode', 'smooth_progressive')
                quality = st.session_state.get('subtitle_quality', 'high')
                
                if display_mode in ['smooth_progressive', 'stable_blocks', 'fade_transitions']:
                    # Sprawd≈∫ jako≈õƒá word-level timestamps
                    word_count = sum(len(seg.get('words', [])) for seg in smooth_segments)
                    estimated_count = sum(
                        sum(1 for w in seg.get('words', []) if w.get('estimated', False)) 
                        for seg in smooth_segments
                    )
                    
                    if word_count > 0:
                        word_level_quality = 1.0 - (estimated_count / word_count)
                        
                        if word_level_quality > 0.8:
                            quality_msg = f"üéØ U≈ºywam precyzyjnych word-level timestamps z AssemblyAI ({word_level_quality:.1%} jako≈õci)"
                        else:
                            quality_msg = f"‚ö†Ô∏è Mieszane timestampy: {word_count-estimated_count} precyzyjnych, {estimated_count} oszacowanych"
                    else:
                        quality_msg = "üìù U≈ºywam oszacowanych timestamp√≥w z segment√≥w"
                    
                    if st.session_state.get('enable_anti_flicker', True):
                        if quality == 'premium':
                            subtitle_content = self.smooth_renderer.generate_high_quality_ass(smooth_segments)
                            st.success(f"‚ú® Napisy Premium ASS z word-level precision + eliminacja migotania")
                            st.info(quality_msg)
                        else:
                            subtitle_content = self.smooth_renderer.generate_smooth_srt(smooth_segments, display_mode)
                            st.success(f"‚ú® P≈Çynne napisy bez migotania - tryb: {display_mode}")
                            st.info(quality_msg)
                    else:
                        subtitle_content = self.smooth_renderer.generate_smooth_srt(smooth_segments, display_mode)
                        st.info(f"üéØ Tryb: {display_mode}")
                        st.info(quality_msg)
                elif display_mode == 'youtube_style':
                    subtitle_content = self.word_level_sync.generate_progressive_srt(word_segments)
                    max_words = st.session_state.get('max_words_on_screen', 8)
                    st.info(f"üéØ U≈ºywam stylu YouTube - s≈Çowa dochodzƒÖ do wypowiedzi (max {max_words} s≈Ç√≥w na ekranie)")
                else:
                    subtitle_content = self.word_level_sync.generate_word_level_srt(word_segments)
                    st.info("üéØ U≈ºywam indywidualnego wy≈õwietlania - tylko jedno s≈Çowo na raz")
                
                # Zapisz informacje o segmentach s≈Ç√≥w dla dalszego przetwarzania
                st.session_state['word_segments'] = word_segments
                
            else:
                progress_tracker.update_progress(0.8, "üìù Generowanie tradycyjnych napis√≥w...")
                subtitle_content = self.subtitle_generator.generate_subtitles(
                    transcript['segments'],
                    translated_text,
                    format=st.session_state.get('subtitle_format', 'SRT'),
                    max_chars_per_line=st.session_state.get('max_chars_per_line', 42)
                )
            
            # Krok 7: Tworzenie wideo z napisami
            progress_tracker.update_progress(0.9, "üé¨ Tworzenie wideo z napisami...")
            output_video_path = self.video_processor.add_subtitles_to_video(
                video_path,
                subtitle_content,
                st.session_state.get('subtitle_format', 'SRT')
            )
            
            # Krok 8: Zako≈Ñczenie
            progress_tracker.update_progress(1.0, "‚úÖ Przetwarzanie zako≈Ñczone!")
            
            # Wy≈õwietl rezultaty
            self._display_results(output_video_path, subtitle_content, original_filename)
            
        except Exception as e:
            logger.error(f"B≈ÇƒÖd podczas przetwarzania: {str(e)}")
            st.error(f"‚ùå WystƒÖpi≈Ç b≈ÇƒÖd: {str(e)}")
        
        finally:
            # Wyczy≈õƒá pliki tymczasowe
            self._cleanup_temp_files([video_path, audio_path if 'audio_path' in locals() else None])
    
    def _execute_with_retry_sync(self, operation: Callable, operation_name: str, *args, **kwargs) -> Tuple[Any, int]:
        """
        Synchroniczna wersja execute_with_retry dla kompatybilno≈õci ze Streamlit
        
        Args:
            operation: Funkcja do wykonania
            operation_name: Nazwa operacji
            *args, **kwargs: Argumenty dla operacji
            
        Returns:
            Tuple (result, retry_count)
        """
        retry_count = 0
        last_exception = None
        
        for attempt in range(self.retry_manager.config.max_retries + 1):
            try:
                start_time = time.time()
                result = operation(*args, **kwargs)
                execution_time = time.time() - start_time
                
                # Sprawd≈∫ jako≈õƒá wyniku
                if self.retry_manager._validate_result_quality(result, operation_name):
                    logger.info(f"{operation_name} zako≈Ñczona pomy≈õlnie po {attempt + 1} pr√≥bach")
                    self.retry_manager._record_successful_attempt(operation_name, execution_time, retry_count)
                    return result, retry_count
                else:
                    raise Exception(f"Wynik operacji {operation_name} nie spe≈Çnia kryteri√≥w jako≈õci")
                    
            except Exception as e:
                last_exception = e
                retry_count += 1
                
                logger.warning(f"{operation_name} - pr√≥ba {attempt + 1} nieudana: {str(e)}")
                
                if attempt < self.retry_manager.config.max_retries:
                    delay = self.retry_manager._calculate_retry_delay(attempt)
                    logger.info(f"Ponowna pr√≥ba za {delay:.1f} sekund...")
                    
                    self.retry_manager._record_failed_attempt(operation_name, str(e), attempt + 1)
                    time.sleep(delay)
                else:
                    logger.error(f"{operation_name} - wszystkie pr√≥by wyczerpane")
        
        # Wszystkie pr√≥by nieudane
        self.retry_manager._record_final_failure(operation_name, str(last_exception), retry_count)
        raise Exception(f"Operacja {operation_name} nieudana po {retry_count} pr√≥bach: {last_exception}")
    
    def _reprocess_segments_sync(self, segments: List[Dict], confidence_threshold: float = 0.6) -> List[Dict]:
        """
        Synchroniczne ponowne przetwarzanie segment√≥w o niskiej pewno≈õci
        
        Args:
            segments: Lista segment√≥w
            confidence_threshold: Pr√≥g pewno≈õci
            
        Returns:
            Lista przetworzonych segment√≥w
        """
        reprocessed_segments = []
        
        for i, segment in enumerate(segments):
            confidence = segment.get('confidence', 1.0)
            
            if confidence < confidence_threshold:
                logger.info(f"Ponowne przetwarzanie segmentu {i} (pewno≈õƒá: {confidence:.2f})")
                
                try:
                    # Ponowne t≈Çumaczenie
                    original_text = segment.get('original_text', segment.get('text', ''))
                    if original_text:
                        retranslated, _ = self._execute_with_retry_sync(
                            self.translation_service.translate_text,
                            "segment_retranslation",
                            original_text,
                            target_language=segment.get('target_language', 'PL')
                        )
                        
                        segment['text'] = retranslated
                        segment['reprocessed'] = True
                        segment['original_confidence'] = confidence
                        segment['confidence'] = min(confidence + 0.2, 1.0)  # Zwiƒôksz pewno≈õƒá
                
                except Exception as e:
                    logger.error(f"B≈ÇƒÖd podczas ponownego przetwarzania segmentu {i}: {e}")
                    segment['reprocessing_failed'] = True
            
            reprocessed_segments.append(segment)
        
        return reprocessed_segments
    
    def _convert_to_smooth_format(self, word_segments):
        """
        Konwertuj segmenty s≈Ç√≥w do formatu kompatybilnego z smooth renderer
        
        Args:
            word_segments: Segmenty z WordLevelSynchronizer
            
        Returns:
            Segmenty w formacie dla SmoothSubtitleRenderer
        """
        smooth_segments = []
        
        for segment in word_segments:
            if hasattr(segment, 'words'):
                # WordLevelSegment object
                words_list = []
                for word in segment.words:
                    word_dict = {
                        'word': word.word,
                        'start': word.start,
                        'end': word.end,
                        'confidence': word.confidence,
                        'speaker': word.speaker
                    }
                    words_list.append(word_dict)
                
                smooth_segment = {
                    'words': words_list,
                    'sentence_id': segment.sentence_id,
                    'complete_text': segment.complete_text
                }
                smooth_segments.append(smooth_segment)
            else:
                # Already in dict format
                smooth_segments.append(segment)
        
        return smooth_segments
    
    def _convert_utterances_to_segments(self, utterances):
        """
        Konwertuj utterances z powrotem do formatu segment√≥w
        
        Args:
            utterances: Lista UtteranceSegment
            
        Returns:
            Lista segment√≥w w standardowym formacie
        """
        segments = []
        
        for utterance in utterances:
            segment = {
                'text': utterance.text,
                'start': utterance.start,
                'end': utterance.end,
                'confidence': utterance.confidence,
                'speaker': utterance.speaker,
                'words': utterance.words,
                'pause_before': utterance.pause_before,
                'pause_after': utterance.pause_after,
                'is_natural_break': utterance.is_natural_break,
                'segment_id': utterance.segment_id
            }
            segments.append(segment)
        
        return segments
    
    def _auto_fix_timestamp_issues(self, transcript: Dict, issues: List) -> Dict:
        """
        Automatycznie napraw podstawowe problemy z timestampami
        
        Args:
            transcript: Dane transkrypcji
            issues: Lista problem√≥w
            
        Returns:
            Naprawione dane transkrypcji
        """
        fixed_transcript = transcript.copy()
        segments = fixed_transcript.get('segments', [])
        
        if not segments:
            return fixed_transcript
        
        logger.info("üîß Automatyczne naprawy timestamp√≥w...")
        
        # 1. Napraw nak≈ÇadajƒÖce siƒô segmenty
        for i in range(len(segments) - 1):
            current_segment = segments[i]
            next_segment = segments[i + 1]
            
            current_end = current_segment.get('end', 0)
            next_start = next_segment.get('start', 0)
            
            if current_end > next_start:
                # Napraw nak≈Çadanie
                gap = 0.1  # 100ms przerwy
                middle_point = (current_end + next_start) / 2
                
                segments[i]['end'] = middle_point - gap/2
                segments[i + 1]['start'] = middle_point + gap/2
                
                logger.debug(f"Naprawiono nak≈Çadanie segment√≥w {i}-{i+1}")
        
        # 2. Napraw bardzo kr√≥tkie segmenty
        for i, segment in enumerate(segments):
            start = segment.get('start', 0)
            end = segment.get('end', 0)
            duration = end - start
            
            if duration < 0.1:
                # Wyd≈Çu≈º segment do minimum 300ms
                min_duration = 0.3
                segments[i]['end'] = start + min_duration
                
                # Sprawd≈∫ czy nie koliduje z nastƒôpnym
                if i < len(segments) - 1:
                    next_start = segments[i + 1].get('start', 0)
                    if segments[i]['end'] > next_start:
                        segments[i]['end'] = next_start - 0.05
                
                logger.debug(f"Wyd≈Çu≈ºono kr√≥tki segment {i}")
        
        # 3. Napraw nieprawid≈Çowe zakresy (end <= start)
        for i, segment in enumerate(segments):
            start = segment.get('start', 0)
            end = segment.get('end', 0)
            
            if end <= start:
                # Ustaw minimalnƒÖ d≈Çugo≈õƒá
                segments[i]['end'] = start + 0.5
                logger.debug(f"Naprawiono nieprawid≈Çowy zakres segmentu {i}")
        
        # 4. Napraw word-level timestamps je≈õli dostƒôpne
        words = fixed_transcript.get('words', [])
        if words:
            fixed_words = self._fix_word_timestamps(words)
            fixed_transcript['words'] = fixed_words
        
        # 5. Dodaj offset je≈õli wszystkie timestampy zaczynajƒÖ siƒô za wcze≈õnie
        first_segment_start = segments[0].get('start', 0) if segments else 0
        if first_segment_start < 0.1:  # Zaczyna siƒô bardzo wcze≈õnie
            offset = 0.3  # Dodaj 300ms offset
            
            for segment in segments:
                segment['start'] = segment.get('start', 0) + offset
                segment['end'] = segment.get('end', 0) + offset
            
            for word in words:
                word['start'] = word.get('start', 0) + offset
                word['end'] = word.get('end', 0) + offset
            
            logger.info(f"Dodano offset {offset}s do wszystkich timestamp√≥w")
        
        fixed_transcript['segments'] = segments
        logger.info("‚úÖ Automatyczne naprawy timestamp√≥w zako≈Ñczone")
        
        return fixed_transcript
    
    def _fix_word_timestamps(self, words: List[Dict]) -> List[Dict]:
        """
        Napraw word-level timestamps
        
        Args:
            words: Lista s≈Ç√≥w
            
        Returns:
            Naprawione s≈Çowa
        """
        if not words:
            return words
        
        fixed_words = []
        
        for i, word in enumerate(words):
            fixed_word = word.copy()
            
            start = word.get('start', 0)
            end = word.get('end', 0)
            duration = end - start
            
            # Napraw bardzo kr√≥tkie s≈Çowa
            if duration < 0.05:  # < 50ms
                min_duration = max(0.08, len(word.get('text', '')) * 0.06)  # ~60ms na znak
                fixed_word['end'] = start + min_duration
            
            # Napraw bardzo d≈Çugie s≈Çowa
            elif duration > 2.0:  # > 2s
                max_duration = min(2.0, len(word.get('text', '')) * 0.15)  # ~150ms na znak
                fixed_word['end'] = start + max_duration
            
            # Napraw nak≈Çadanie z nastƒôpnym s≈Çowem
            if i < len(words) - 1:
                next_start = words[i + 1].get('start', 0)
                if fixed_word['end'] > next_start:
                    gap = 0.02  # 20ms przerwy
                    fixed_word['end'] = next_start - gap
                    
                    # Upewnij siƒô ≈ºe s≈Çowo ma minimalnƒÖ d≈Çugo≈õƒá
                    if fixed_word['end'] - fixed_word['start'] < 0.05:
                        fixed_word['end'] = fixed_word['start'] + 0.05
            
            fixed_words.append(fixed_word)
        
        return fixed_words
    
    def _display_results(self, output_video_path: str, subtitle_content: str, original_filename: str):
        """Wy≈õwietl rezultaty przetwarzania"""
        st.success("üéâ Przetwarzanie zako≈Ñczone pomy≈õlnie!")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üé¨ Wideo z napisami")
            VideoPlayer.render_video_player(output_video_path)
            
            # Przycisk pobierania wideo
            with open(output_video_path, 'rb') as f:
                st.download_button(
                    label="üì• Pobierz wideo z napisami",
                    data=f.read(),
                    file_name=f"translated_{original_filename}",
                    mime="video/mp4"
                )
        
        with col2:
            st.subheader("üìù Napisy")
            st.text_area(
                "Wygenerowane napisy:",
                subtitle_content,
                height=300,
                help="Mo≈ºesz skopiowaƒá napisy lub pobraƒá jako plik"
            )
            
            # Przycisk pobierania napis√≥w
            subtitle_filename = f"subtitles_{original_filename.rsplit('.', 1)[0]}.{st.session_state.get('subtitle_format', 'srt').lower()}"
            st.download_button(
                label="üì• Pobierz napisy",
                data=subtitle_content,
                file_name=subtitle_filename,
                mime="text/plain"
            )
    
    def _display_results_with_quality_report(self, 
                                           output_video_path: str, 
                                           subtitle_content: str, 
                                           original_filename: str,
                                           quality_report=None,
                                           transcript=None,
                                           translated_segments=None):
        """Wy≈õwietl rezultaty przetwarzania z raportem jako≈õci"""
        st.success("üéâ Przetwarzanie zako≈Ñczone pomy≈õlnie!")
        
        # G≈Ç√≥wne rezultaty
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üé¨ Wideo z napisami")
            VideoPlayer.render_video_player(output_video_path)
            
            # Przycisk pobierania wideo
            with open(output_video_path, 'rb') as f:
                st.download_button(
                    label="üì• Pobierz wideo z napisami",
                    data=f.read(),
                    file_name=f"translated_{original_filename}",
                    mime="video/mp4"
                )
        
        with col2:
            st.subheader("üìù Napisy")
            st.text_area(
                "Wygenerowane napisy:",
                subtitle_content,
                height=300,
                help="Mo≈ºesz skopiowaƒá napisy lub pobraƒá jako plik"
            )
            
            # Przycisk pobierania napis√≥w
            subtitle_filename = f"subtitles_{original_filename.rsplit('.', 1)[0]}.{st.session_state.get('subtitle_format', 'srt').lower()}"
            st.download_button(
                label="üì• Pobierz napisy",
                data=subtitle_content,
                file_name=subtitle_filename,
                mime="text/plain"
            )
        
        # Raport jako≈õci
        if quality_report:
            st.subheader("üìä Raport jako≈õci")
            self._display_quality_metrics(quality_report)
        
        # Informacje o m√≥wiƒÖcych
        if transcript and transcript.get('segments'):
            st.subheader("üë• Analiza m√≥wiƒÖcych")
            self._display_speaker_analysis(transcript)
        
        # Statystyki przetwarzania
        st.subheader("üìà Statystyki przetwarzania")
        self._display_processing_statistics()
        
        # Informacje o napisach na poziomie s≈Ç√≥w
        if 'word_segments' in st.session_state:
            st.subheader("üî§ Analiza napis√≥w na poziomie s≈Ç√≥w")
            self._display_word_level_analysis()
        
        # Informacje o segmentacji utterances
        if 'utterance_segments' in st.session_state:
            st.subheader("üó£Ô∏è Analiza segmentacji utterances")
            self._display_utterance_analysis()
    
    def _display_quality_metrics(self, quality_report):
        """Wy≈õwietl metryki jako≈õci"""
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                "Og√≥lna jako≈õƒá",
                quality_report.overall_quality.value.title(),
                delta=None
            )
            
            confidence = quality_report.confidence_metrics.overall_confidence
            st.metric(
                "Pewno≈õƒá og√≥lna",
                f"{confidence:.1%}",
                delta=f"{(confidence - 0.7):.1%}" if confidence != 0.7 else None
            )
        
        with col2:
            st.metric(
                "Pewno≈õƒá transkrypcji",
                f"{quality_report.confidence_metrics.transcription_confidence:.1%}"
            )
            
            st.metric(
                "Pewno≈õƒá t≈Çumaczenia",
                f"{quality_report.confidence_metrics.translation_confidence:.1%}"
            )
        
        with col3:
            st.metric(
                "Czas przetwarzania",
                f"{quality_report.processing_time:.1f}s"
            )
            
            st.metric(
                "Liczba ponownych pr√≥b",
                quality_report.retry_count
            )
        
        # Problemy i rekomendacje
        if quality_report.timing_issues or quality_report.translation_issues:
            st.subheader("‚ö†Ô∏è Wykryte problemy")
            
            if quality_report.timing_issues:
                st.warning("**Problemy z timingiem:**")
                for issue in quality_report.timing_issues:
                    st.write(f"‚Ä¢ {issue}")
            
            if quality_report.translation_issues:
                st.warning("**Problemy z t≈Çumaczeniem:**")
                for issue in quality_report.translation_issues:
                    st.write(f"‚Ä¢ {issue}")
        
        if quality_report.recommendations:
            st.subheader("üí° Rekomendacje")
            for rec in quality_report.recommendations:
                st.info(f"‚Ä¢ {rec}")
    
    def _display_speaker_analysis(self, transcript):
        """Wy≈õwietl analizƒô m√≥wiƒÖcych"""
        speaker_analysis = self.quality_controller.analyze_speakers(transcript)
        
        if len(speaker_analysis) > 1:
            st.write(f"**Wykryto {len(speaker_analysis)} m√≥wiƒÖcych:**")
            
            for speaker in speaker_analysis:
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.write(f"**{speaker.speaker_id}**")
                
                with col2:
                    st.write(f"Segment√≥w: {speaker.segments_count}")
                
                with col3:
                    st.write(f"Czas: {speaker.total_duration:.1f}s")
                    st.write(f"Pewno≈õƒá: {speaker.confidence:.1%}")
        else:
            st.write("**Wykryto jednego m√≥wiƒÖcego**")
    
    def _display_processing_statistics(self):
        """Wy≈õwietl statystyki przetwarzania"""
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üé§ Transkrypcja")
            if hasattr(self.transcription_service, 'processing_times') and self.transcription_service.processing_times:
                avg_time = sum(self.transcription_service.processing_times) / len(self.transcription_service.processing_times)
                st.metric("≈öredni czas", f"{avg_time:.1f}s")
                
                if self.transcription_service.confidence_scores:
                    avg_confidence = sum(self.transcription_service.confidence_scores) / len(self.transcription_service.confidence_scores)
                    st.metric("≈örednia pewno≈õƒá", f"{avg_confidence:.1%}")
        
        with col2:
            st.subheader("üåç T≈Çumaczenie")
            if hasattr(self.translation_service, 'translation_times') and self.translation_service.translation_times:
                stats = self.translation_service.get_translation_statistics()
                if stats:
                    st.metric("≈öredni czas", f"{stats['average_time']:.1f}s")
                    st.metric("≈örednia jako≈õƒá", f"{stats['average_quality']:.1%}")
        
        # Statystyki ponownych pr√≥b
        retry_stats = self.retry_manager.get_retry_statistics()
        if retry_stats:
            st.subheader("üîÑ Ponowne pr√≥by")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Sukces", f"{retry_stats['success_rate']:.1f}%")
            
            with col2:
                st.metric("≈örednie pr√≥by", f"{retry_stats['average_retry_count']:.1f}")
            
            with col3:
                st.metric("Operacje", retry_stats['total_operations'])
    
    def _display_error_statistics(self):
        """Wy≈õwietl statystyki b≈Çƒôd√≥w"""
        st.subheader("üìä Statystyki sesji")
        
        retry_stats = self.retry_manager.get_retry_statistics()
        if retry_stats:
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("Udane operacje", retry_stats['successful_operations'])
                st.metric("Nieudane operacje", retry_stats['failed_operations'])
            
            with col2:
                st.metric("Wska≈∫nik sukcesu", f"{retry_stats['success_rate']:.1f}%")
                st.metric("≈öredni czas", f"{retry_stats['average_execution_time']:.1f}s")
    
    def _convert_stabilized_blocks_to_segments(self, stabilized_blocks):
        """
        Konwertuj stabilizowane bloki do formatu word_segments dla kompatybilno≈õci
        """
        from .services.word_level_sync import WordLevelSegment
        
        word_segments = []
        for block in stabilized_blocks:
            segment = WordLevelSegment(
                sentence_id=block.block_id,
                words=block.words,
                sentence_start=block.start_time,
                sentence_end=block.end_time,
                complete_text=' '.join([w.word for w in block.words])
            )
            word_segments.append(segment)
        
        return word_segments
    
    def _display_word_level_analysis(self):
        """Wy≈õwietl analizƒô napis√≥w na poziomie s≈Ç√≥w"""
        word_segments = st.session_state.get('word_segments', [])
        
        if not word_segments:
            return
        
        # Oblicz statystyki
        total_words = sum(len(segment.words) for segment in word_segments)
        total_sentences = len(word_segments)
        
        # ≈örednia d≈Çugo≈õƒá s≈Çowa
        word_durations = []
        for segment in word_segments:
            for word in segment.words:
                duration = word.end - word.start
                word_durations.append(duration)
        
        avg_word_duration = np.mean(word_durations) if word_durations else 0
        
        # ≈örednia pewno≈õƒá s≈Ç√≥w
        word_confidences = []
        for segment in word_segments:
            for word in segment.words:
                word_confidences.append(word.confidence)
        
        avg_word_confidence = np.mean(word_confidences) if word_confidences else 0
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Ca≈Çkowita liczba s≈Ç√≥w", total_words)
            st.metric("Liczba zda≈Ñ", total_sentences)
        
        with col2:
            st.metric("≈örednia d≈Çugo≈õƒá s≈Çowa", f"{avg_word_duration:.2f}s")
            st.metric("S≈Ç√≥w na zdanie", f"{total_words/total_sentences:.1f}" if total_sentences > 0 else "0")
        
        with col3:
            st.metric("≈örednia pewno≈õƒá s≈Ç√≥w", f"{avg_word_confidence:.1%}")
            
            # Tryb wy≈õwietlania
            display_mode = st.session_state.get('word_display_mode', 'progressive')
            mode_text = "Progresywny" if display_mode == 'progressive' else "Indywidualny"
            st.metric("Tryb wy≈õwietlania", mode_text)
        
        # Szczeg√≥≈Çowa analiza pierwszych kilku zda≈Ñ
        st.subheader("üîç PodglƒÖd pierwszych zda≈Ñ")
        
        for i, segment in enumerate(word_segments[:3]):  # Poka≈º pierwsze 3 zdania
            with st.expander(f"Zdanie {i+1}: '{segment.complete_text}'"):
                st.write(f"**Czas trwania:** {segment.sentence_end - segment.sentence_start:.2f}s")
                st.write(f"**Liczba s≈Ç√≥w:** {len(segment.words)}")
                
                # Tabela s≈Ç√≥w
                word_data = []
                for j, word in enumerate(segment.words):
                    word_data.append({
                        "Nr": j+1,
                        "S≈Çowo": word.word,
                        "Start": f"{word.start:.2f}s",
                        "Koniec": f"{word.end:.2f}s",
                        "D≈Çugo≈õƒá": f"{word.end - word.start:.2f}s",
                        "Pewno≈õƒá": f"{word.confidence:.1%}"
                    })
                
                st.table(word_data)
        
        # Informacje o korzy≈õciach
        st.info("""
        **Korzy≈õci z napis√≥w na poziomie s≈Ç√≥w:**
        
        üéØ **Lepsza synchronizacja** - ka≈ºde s≈Çowo ma precyzyjny timing
        
        üì∫ **Naturalne czytanie** - s≈Çowa pojawiajƒÖ siƒô jak w naturalnej mowie
        
        üé¨ **Profesjonalny wyglƒÖd** - jak w filmach i programach TV
        
        ‚ôø **Dostƒôpno≈õƒá** - ≈Çatwiejsze dla os√≥b z problemami s≈Çuchu
        
        üß† **Lepsze zrozumienie** - m√≥zg ≈Çatwiej przetwarza stopniowo pojawiajƒÖce siƒô s≈Çowa
        """)
        
        # Por√≥wnanie z tradycyjnymi napisami
        st.subheader("üìä Por√≥wnanie z tradycyjnymi napisami")
        
        comparison_data = {
            "Aspekt": [
                "Synchronizacja",
                "Naturalno≈õƒá",
                "Czytelno≈õƒá",
                "Precyzja timingu",
                "Do≈õwiadczenie u≈ºytkownika"
            ],
            "Tradycyjne napisy": [
                "Segmenty (2-5s)",
                "Sztuczne bloki tekstu",
                "Dobra",
                "Przybli≈ºona",
                "Standardowa"
            ],
            "Napisy na poziomie s≈Ç√≥w": [
                "Ka≈ºde s≈Çowo osobno",
                "Jak naturalna mowa",
                "Doskona≈Ça",
                "Precyzyjna",
                "Premium"
            ]
        }
        
        st.table(comparison_data)
    
    def _display_utterance_analysis(self):
        """Wy≈õwietl analizƒô segmentacji utterances"""
        utterance_segments = st.session_state.get('utterance_segments', [])
        pause_stats = st.session_state.get('pause_statistics', {})
        
        if not utterance_segments:
            return
        
        # Podstawowe statystyki
        total_utterances = len(utterance_segments)
        natural_breaks = sum(1 for u in utterance_segments if u.is_natural_break)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Liczba utterances", total_utterances)
            st.metric("Naturalne przerwy", f"{natural_breaks}/{total_utterances}")
        
        with col2:
            if pause_stats:
                st.metric("≈örednia pauza", f"{pause_stats.get('average_pause', 0):.2f}s")
                st.metric("Maksymalna pauza", f"{pause_stats.get('max_pause', 0):.2f}s")
        
        with col3:
            if pause_stats:
                st.metric("Ca≈Çkowity czas pauz", f"{pause_stats.get('total_pause_time', 0):.1f}s")
                st.metric("Pauzy > 1s", pause_stats.get('pauses_over_1s', 0))
        
        # Szczeg√≥≈Çowa analiza pierwszych utterances
        st.subheader("üîç PodglƒÖd pierwszych utterances")
        
        for i, utterance in enumerate(utterance_segments[:3]):
            with st.expander(f"Utterance {i+1}: '{utterance.text[:50]}...'"):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write(f"**Czas:** {utterance.start:.2f}s - {utterance.end:.2f}s")
                    st.write(f"**D≈Çugo≈õƒá:** {utterance.end - utterance.start:.2f}s")
                    st.write(f"**M√≥wiƒÖcy:** {utterance.speaker}")
                    st.write(f"**Pewno≈õƒá:** {utterance.confidence:.1%}")
                
                with col2:
                    st.write(f"**Pauza przed:** {utterance.pause_before:.2f}s")
                    st.write(f"**Pauza po:** {utterance.pause_after:.2f}s")
                    st.write(f"**Naturalna przerwa:** {'‚úÖ' if utterance.is_natural_break else '‚ùå'}")
                    st.write(f"**Liczba s≈Ç√≥w:** {len(utterance.words)}")
                
                st.write(f"**Pe≈Çny tekst:** {utterance.text}")
        
        # Informacje o korzy≈õciach
        st.info("""
        **Korzy≈õci z segmentacji utterances:**
        
        üéØ **Naturalne przerwy** - podzia≈Ç tam gdzie rzeczywi≈õcie sƒÖ pauzy w mowie
        
        üìä **Automatyczne wykrywanie** - AssemblyAI automatycznie znajduje ciszƒô
        
        üó£Ô∏è **Lepsze grupowanie** - wypowiedzi grupowane logicznie
        
        ‚è±Ô∏è **Precyzyjne pauzy** - dok≈Çadne informacje o d≈Çugo≈õci przerw
        
        üé¨ **Profesjonalne napisy** - jak w filmach i programach TV
        """)
        
        # Wykres rozk≈Çadu d≈Çugo≈õci utterances
        if len(utterance_segments) > 1:
            st.subheader("üìä Rozk≈Çad d≈Çugo≈õci utterances")
            
            durations = [u.end - u.start for u in utterance_segments]
            
            import matplotlib.pyplot as plt
            import numpy as np
            
            fig, ax = plt.subplots(figsize=(10, 4))
            ax.hist(durations, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
            ax.set_xlabel('D≈Çugo≈õƒá utterance (sekundy)')
            ax.set_ylabel('Liczba utterances')
            ax.set_title('Rozk≈Çad d≈Çugo≈õci utterances')
            ax.grid(True, alpha=0.3)
            
            st.pyplot(fig)
            plt.close()
    
    def _cleanup_temp_files(self, file_paths: list):
        """Wyczy≈õƒá pliki tymczasowe"""
        for file_path in file_paths:
            if file_path and os.path.exists(file_path):
                try:
                    os.unlink(file_path)
                except Exception as e:
                    logger.warning(f"Nie mo≈ºna usunƒÖƒá pliku tymczasowego {file_path}: {e}")

def run_app():
    """Funkcja uruchamiajƒÖca aplikacjƒô"""
    app = VideoSubtitleApp()
    app.run()